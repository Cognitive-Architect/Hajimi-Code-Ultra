

# HAJIMI-PHASE2-DEEPRESEARCH-001 六线并行设计集群白皮书

**文档版本**: v1.0.0-final  
**冻结日期**: 2026-02-17  
**总篇幅**: 67KB（六份白皮书合计）  
**额度消耗**: 3-4点（Hajimi-Unified单窗批处理模式）

---

## 1. 执行摘要与战术框架

### 1.1 饱和攻击波次定义

#### 1.1.1 六线并行火力配置

HAJIMI-PHASE2-DEEPRESEARCH-001 代表 Hajimi 项目第二阶段的深度研究饱和攻击波次，其核心特征在于采用**六线并行设计集群**的火力配置模式，通过单窗批处理技术实现资源效率最大化。该战术配置部署 **6 个专门化设计 Agent**，每条路线由独特角色人格驱动，在单一 AI 交互窗口内模拟并行思考过程：

| 路线 | 角色人格 | 职能定位 | 核心产出 |
|:---|:---|:---|:---|
| A/06 | 🟢 黄瓜睦（Architect） | 系统架构裁决 | 本地Context运行时（LCR）终极架构 |
| B/06 | 🩷 唐音（Engineer） | 工程实现 | 技术栈一键切换引擎（Polyglot Adapter） |
| C/06 | 💛 Soyorin（PM） | 产品集成 | MCP协议桥接层 |
| D/06 | 🩵 咕咕嘎嘎（QA） | 质量保障 | 情报抓取系统（Hajimi Claw） |
| E/06 | 🟣 客服小祥（Orchestrator） | 运维协调 | v1.4.0桌面产品化 |
| F/06 | 🔵 压力怪（Audit） | 风险管控 | 债务自动化清偿（AutoPay） |

六线并行的战术目标是在**单一时间窗口内同步冻结六条技术路线的白皮书设计**，将传统串行开发模式的时间成本压缩至极限。这种饱和攻击策略的本质在于：通过高度并行的设计探索，将架构风险前置到文档阶段，避免后期实现阶段的昂贵返工。

#### 1.1.2 单窗批处理Hajimi-Unified模式

**Hajimi-Unified 模式**是本项目的核心创新机制，被内部代号称为**"一元九头蛇"秘技**。其技术本质在于：用单个窗口的单个额度，模拟出 6 个独立 Agent 的并行思考过程——而非传统方案中真开 6 个窗口（消耗 6 点额度）。实现机制上，AI 在同一个 response 内分块输出，每块携带不同角色人格标记（黄瓜睦/唐音/Soyorin/咕咕嘎嘎/客服小祥/压力怪），通过人格切换实现思维视角的并行切换。

| 模式对比 | 多窗口并行 | Hajimi-Unified |
|:---|:---|:---|
| 额度消耗 | 6点 | **3-4点**（节省33%-50%） |
| 上下文共享 | 弱（窗口隔离） | **强**（统一基线） |
| 协调成本 | 高（显式同步） | **低**（内置约束） |
| 输出一致性 | 易发散 | **强制收敛** |

该模式的核心挑战在于**如何保证六路不打架、能会师**。解决方案通过四层约束机制实现：

| 约束机制 | 核心作用 | 工程类比 |
|:---|:---|:---|
| **共享基线** | 六路都基于 v1.4.0-final 架构延伸 | 盖楼时站在同一层地基上 |
| **统一债务语言** | P0/P1/P2 分级 + DEBT-XXX 编号 | 财务报表统一会计科目 |
| **统一自测表格式** | "自测点+负面路径+交付物清单" | ISO 标准验收格式 |
| **Orchestrator 仲裁** | 黄瓜睦（Architect）最高裁决权 | 内阁首相，部长吵架首相拍板 |

#### 1.1.3 设计冻结目标与验收标准

**设计冻结**在本项目中的技术含义是：接口契约成为绑定规范、性能预算成为强制约束、验证标准成为验收依据。冻结发生在**文档阶段而非实现阶段**，这是"风险前置"哲学的核心体现——在投入昂贵开发资源之前，充分暴露架构冲突、接口不匹配和集成挑战。

每条路线设定**三级自测点（Self-Test Points）**，形成可量化、可验证的交付门槛：

| 路线 | 自测点编号 | 指标定义 | 目标值 |
|:---|:---|:---|:---|
| A | ARC-001 | 协议压缩率 | **>80%** |
| A | ARC-002 | 语义检索延迟 | **<50ms** |
| A | ARC-003 | GC 停顿时间 | **<100ms** |
| B | POL-001 | Node 转 Python 准确率 | **>95%** |
| B | POL-002 | 技术栈切换延迟 | **<30s** |
| B | POL-003 | 类型信息丢失率 | **<2%** |
| C | MCP-001 | 工具发现延迟 | **<100ms** |
| C | MCP-002 | 文件读写隔离 | **验证通过** |
| C | MCP-003 | 危险命令拦截率 | **100%** |
| D | CLAW-001 | 日抓取量 | **>100篇** |
| D | CLAW-002 | 去重准确率 | **>98%** |
| D | CLAW-003 | 简报生成时间 | **<60s** |
| E | DSK-001 | 安装包体积 | **<100MB** |
| E | DSK-002 | 冷启动时间 | **<3s** |
| E | DSK-003 | 自动更新中断 | **零中断** |
| F | PAY-001 | 季度指纹更新人工介入 | **零人工** |
| F | PAY-002 | 自动合并前审计通过 | **100%** |
| F | PAY-003 | 超支熔断响应时间 | **<5s** |

### 1.2 输入基线与约束条件

#### 1.2.1 ID-96 v1.4.0-final架构基线

**ID-96 v1.4.0-final** 作为六线并行的统一输入基线，代表了 Hajimi 项目第一阶段的完整技术沉淀。该基线的"final"状态意味着：核心架构模式已验证稳定，接口契约已冻结，技术债务已清点，可作为衍生设计的可靠地基。

基线的核心组成可从各路线的输入引用中推断：

| 技术储备 | 来源标识 | 核心贡献 |
|:---|:---|:---|
| Factory 模式 | v1.4.0 代码结构 | 可扩展的组件实例化框架 |
| A2A 消息格式 | 现有消息总线 | Agent 间通信标准 |
| 七权权限模型 | 现有安全体系 | 角色分级访问控制 |
| 9 项技术债务 | v1.4.0 债务清单 | AutoPay 的清偿对象 |
| lib/ 目录结构 | 现有代码组织 | Desktop 产品化的保留目标 |

**共享基线约束**的技术含义：所有六条路线必须从 v1.4.0-final 延伸，禁止任何"从零开始"的重新设计。这一约束类比于建筑工程中的"同一层地基"原则——六栋大楼功能各异，但必须建立在完全一致的承重结构之上，确保最终能够无缝拼接。

#### 1.2.2 六方向需求摘要整合

六条路线的需求来源反映了 Hajimi 生态的完整技术栈覆盖：

| 路线 | 需求来源 | 核心痛点 | 设计响应 |
|:---|:---|:---|:---|
| A | ID-94 技术储备 + ID-93 GC 体系 + MemGPT 论文 | 云端上下文隐私风险与延迟 | **本地 context-rich，云端 contextless** |
| B | v1.4.0 Factory 模式 + AST 理论 + Protobuf | 多语言生态的重复开发成本 | **秒级技术栈切换，IR 中间表示** |
| C | Anthropic MCP 协议 + Alice UI 现状 + 本地权限 | AI 助手无法操控本地资源 | **MCP 桥接，悬浮球系统控制** |
| D | RSS + GitHub API + B站爬虫 + RAG 向量化 | 手动信息监控的低效与遗漏 | **自动化抓取，智能摘要，晨读推送** |
| E | v1.4.0 代码结构 + Electron/Tauri 架构 | CLI 工具的非技术用户门槛 | **双击运行，七权可视化，自动更新** |
| F | 9 项债务 + GitHub Actions + Mike 审计 | 技术债务的积累与遗忘 | **房贷式自动还款，预算熔断** |

#### 1.2.3 "只出设计图"战术原则

本项目的核心约束原则是**"只出设计图，不写实现代码——把风险前置到文档阶段"**。这一原则的底层逻辑在于：小作坊资源有限，必须将额度优先分配给"思考架构"而非"敲代码"，通过设计图阶段锁定接口契约，后续 Atoms 施工队可按图施工、不走样。

| 类别 | 允许交付物 | 禁止交付物 |
|:---|:---|:---|
| **架构表达** | 架构图（文字版/ASCII 艺术） | — |
| **接口契约** | TypeScript interface 定义 | 完整 `npm install` 可运行实现 |
| **数据流** | Mermaid 语法图表 | 具体业务逻辑代码 |
| **算法逻辑** | 核心算法伪代码（标注"// 伪代码，非实现"） | 详细错误处理 catch 块 |

**示例对比**：

✅ **允许**（接口定义）：
```typescript
interface IContextChunk {
  id: string;                    // UUID v4，全局唯一
  content: string;               // UTF-8 文本，最大 64KB
  vector: Float32Array;          // 384 维嵌入向量
  ttl: number;                   // 生存时间（秒），0 表示永久
  createdAt: number;             // Unix 时间戳（毫秒）
}
```

❌ **禁止**（实现代码）：
```typescript
// 不要这种能直接跑的
async function saveChunk(chunk: IContextChunk) {
  await db.collection('chunks').insertOne(chunk); // 具体实现不要
}
```

### 1.3 六线协同机制

#### 1.3.1 共享基线约束

六路设计必须严格基于 **ID-96 v1.4.0-final** 基线进行延伸，这一约束通过三个层次强制执行：

- **技术层次**：兼容 v1.4.0 的模块结构和依赖关系
- **数据层次**：统一采用 DEBT-XXX 编号体系和 P0/P1/P2 分级标准
- **流程层次**：遵循"自测点+负面路径+交付物清单"的 ISO 标准格式

#### 1.3.2 统一债务语言（P0/P1/P2分级）

| 等级 | 定义 | 响应时限 | 典型场景 |
|:---|:---|:---|:---|
| **P0** | 阻塞性债务，系统无法运行 | 立即解决 | 架构冲突导致接口不兼容 |
| **P1** | 重要债务，影响质量或效率 | 当前阶段解决 | 性能预算超标、安全边界模糊 |
| **P2** | 次要债务，可延期处理 | 择机解决 | 文档完善、代码风格统一 |

六线并行固有的三项预声明债务：

| 债务 ID | 内容 | 等级 | 缓解策略 |
|:---|:---|:---|:---|
| DEBT-RES-001 | 六线设计可能存在方案冲突（如 LCR 与 Desktop 资源争夺） | **P1** | Architect 仲裁机制，每周同步会议 |
| DEBT-RES-002 | 深度研究依赖外部资料时效性（MCP 协议可能更新） | **P2** | 版本锁定策略，季度兼容性审查 |
| DEBT-RES-003 | 六份白皮书 review 工作量巨大 | **P1** | 分阶段验收，自动化格式检查 |

#### 1.3.3 统一自测表格式

每条路线的交付物必须包含标准化的**自测表**，格式为：

```
【自测点】量化指标 + 验证方法
【负面路径】未达标时的降级策略或回滚方案
【交付物清单】文档、图表、配置文件的完整枚举
```

#### 1.3.4 Orchestrator仲裁机制

**黄瓜睦（Architect）** 在六线并行过程中拥有最高裁决权。仲裁触发条件包括：资源争夺（如 LCR 内存预算与 Desktop 应用体积冲突）、接口不兼容（如 Polyglot IR 与 MCP 消息格式的序列化差异）、时序依赖（如 Claw 数据输出与 LCR 存储就绪的先后关系）。

仲裁流程：冲突方 48 小时内协商未果 → 提交书面提案 → Architect 24 小时内裁决 → 结果文档化并纳入债务跟踪。

---

## 2. 路线A：上下文主权革命（黄瓜睦/Architect）

### 2.1 本地Context运行时（LCR）终极架构

#### 2.1.1 "云端contextless，本地context-rich"设计哲学

LCR 架构的核心设计目标是实现**"云端 contextless，本地 context-rich"**的上下文主权革命，彻底颠覆传统大语言模型应用对云端上下文存储的依赖。这一设计哲学基于三重技术洞察：

- **隐私合规**：GDPR、CCPA 等法规要求用户数据最小化出境
- **延迟优化**：网络往返引入的百毫秒级延迟无法消除
- **功能完整性**：丰富的个人历史上下文是实现真正个性化 AI 的前提

传统模式的根本矛盾在于：云端模型需要上下文以生成相关响应，但上下文传输带来隐私暴露和性能损耗。LCR 的解决方案是**架构性反转**——将完整的上下文管理能力下沉至用户设备，云端仅接收脱敏后的最小必要信息（如查询意图的向量表示），本地则维护丰富、完整、可审计的上下文状态。

#### 2.1.2 技术储备整合（ID-94 + ID-93 + MemGPT论文）

LCR 架构的创新基础来自三项技术储备的深度整合：

| 技术储备 | 核心贡献 | 在 LCR 中的演进 |
|:---|:---|:---|
| **ID-94 技术储备** | 上下文分片与压缩的工程经验 | **.hctx 工业协议**的差分压缩设计 |
| **ID-93 GC 体系** | 内存管理与生命周期控制的底层能力 | **预测性垃圾回收**的 LSTM+ZGC 方案 |
| **MemGPT 论文** | 分层内存管理的理论框架 | **四层内存架构**的具体参数化 |

这种整合并非简单叠加，而是通过架构创新实现 **1+1+1>3** 的协同效应：MemGPT 的理论分层与 ID-94 的工程实践结合，催生了 .hctx 协议的具体设计；ID-93 的 GC 机制与 MemGPT 的 Archive 层结合，形成了预测性垃圾回收的独特方案。

### 2.2 .hctx工业协议

#### 2.2.1 BSDiff差分压缩算法

**.hctx**（Hajimi Context）文件格式是 LCR 架构的数据交换基石，其压缩层采用 **BSDiff 差分压缩算法**。该算法的选择源于上下文数据的特殊访问模式：相邻版本间的差异通常仅占全量的 5%-15%，远低于通用压缩算法的假设。

BSDiff 的核心机制：
- **分块排序与后缀数组构建**：将新旧版本数据分别预处理
- **差分补丁生成**："复制指令+插入数据"的紧凑表示
- **典型压缩率**：**>80%**（验收指标 ARC-001）

在 LCR 场景中，该算法被适配用于上下文分片的增量同步——当用户在设备 A 上进行了对话，仅需将新增的上下文分片以 BSDiff 格式生成补丁，同步至设备 B 后应用即可恢复完整状态。

#### 2.2.2 SHA256链式完整性校验

SHA256 链式完整性校验机制为上下文数据的可信传输提供密码学保障。每条上下文分片在生成时计算 SHA256 哈希，并将前一分的哈希值纳入当前分的计算输入，形成**不可篡改的审计链条**。

核心特性：
- **篡改检测**：任何单点变更导致后续所有哈希失效
- **高效同步**：设备可快速识别分歧点，仅交换缺失历史
- **密码学修剪**：归档上下文可摘要为哈希承诺，支持存储回收

#### 2.2.3 跨端同步格式规范

.hctx 文件采用分层结构设计：

| 区域 | 内容 | 设计考量 |
|:---|:---|:---|
| **文件头（Header）** | 魔数（0x68435478）、版本号、压缩算法标识 | 快速格式识别 |
| **元数据区（Metadata）** | 同步会话 ID、参与设备列表、时间窗口 | 冲突检测基础 |
| **数据区（Payload）** | BSDiff 差分补丁，分块存储 | 断点续传支持 |
| **校验区（Trailer）** | 哈希链条终点值 | 快速完整性验证 |

### 2.3 MemGPT四层内存架构

LCR 直接借鉴并扩展 MemGPT 论文的分层内存思想，针对本地运行环境设计**四层架构**：

#### 2.3.1 Focus层（<8K tokens）

**Focus 层**对应 LLM 的上下文窗口，严格限制在 **<8K tokens**（可配置）。该层的设计哲学是**"注意力即稀缺资源"**——强制将最活跃、最相关的上下文内容保留在"工作记忆"中。

- **内容选择策略**：时间衰减（最近使用优先）+ 相关性评分（与当前查询的向量相似度）
- **数据结构**：环形缓冲区，新内容写入时自动驱逐最旧内容
- **驱逐触发**：异步归档至 Working 层

#### 2.3.2 Working层（活跃上下文）

**Working 层**作为 Focus 层的缓存扩展，默认容量 **128K tokens**，可根据设备内存动态调整。

- **核心功能**：维护近期活跃但非即时的上下文，支持快速重新激活
- **索引结构**：混合设计——时间序列索引 + 向量索引 + 倒排索引
- **晋升策略**：显式召回或隐式建议（基于当前话题相关性）

#### 2.3.3 Archive层（历史归档）

**Archive 层**处理跨会话的历史数据，采用**分层存储策略**：

| 数据温度 | 存储介质 | 保留策略 |
|:---|:---|:---|
| 热数据（30 天内） | 本地 SSD 的 LevelDB 实例 | 快速访问 |
| 温数据（30-90 天） | 机械硬盘的压缩归档文件 | 成本优化 |
| 冷数据（90 天以上） | 用户控制的加密云存储 | 空间释放 |

与预测性 GC 的协同：LSTM 模型预测未来访问概率，低概率内容优先进入压缩归档。

#### 2.3.4 RAG层（外部知识检索）

**RAG 层**将本地上下文能力与外部知识源无缝整合，突破单一模型参数的知识边界。

- **存储后端**：IndexedDB（浏览器环境）或 SQLite（桌面环境）
- **向量维度**：384 维（all-MiniLM-L6-v2 模型）
- **索引算法**：HNSW（Hierarchical Navigable Small World）近似最近邻
- **目标延迟**：**<50ms**（验收指标 ARC-002）

### 2.4 本地RAG引擎

#### 2.4.1 IndexedDB向量存储设计

浏览器环境的 IndexedDB 作为向量存储后端，面临特殊约束与优化空间：

| 约束 | 优化策略 |
|:---|:---|
| 存储配额限制（50-60% 可用磁盘） | 动态容量管理，用户可配置上限 |
| 异步 API 复杂性 | Promise 化封装，批量操作聚合 |
| 缺乏原生向量操作 | WebGL/WebGPU 加速，SIMD 优化 |

**三层抽象架构**：
- **底层**：IndexedDB 异步操作的 Promise 化 CRUD 接口
- **中层**：HNSW 索引的增量维护，动态插入/删除
- **上层**：语义检索 API，屏蔽向量计算复杂性

#### 2.4.2 语义检索优化（目标<50ms）

| 优化策略 | 机制 | 效果 |
|:---|:---|:---|
| **热点查询缓存** | 内存 LRU 结构 | 命中率 70%+ |
| **GPU 加速计算** | WebGL/WebGPU 点积计算 | 吞吐量提升 10x |
| **内存映射 HNSW** | 磁盘 I/O 最小化 | 亚毫秒索引访问 |
| **激进优化方向** | 原生向量库集成（ONNX Runtime/Core ML） | 接近原生性能 |

### 2.5 预测性垃圾回收

#### 2.5.1 LSTM水位预测模型

**LSTM（Long Short-Term Memory）神经网络**预测内存水位趋势，将被动响应转为主动预防。

- **输入特征**：时间（小时、星期、节假日）、会话特征（主题、Agent、交互频率）、历史特征（过往访问模式、共现关系）
- **输出**：未来 24 小时内各上下文分片的访问概率分布
- **决策阈值**：概率 < 配置阈值 → 进入待清理队列

#### 2.5.2 ZGC零停顿清理策略

**ZGC（Z Garbage Collector）** 作为底层保障，将停顿时间控制在 **<10ms**，满足验收指标 **ARC-003（<100ms）** 的激进目标。

协同机制：
- LSTM 预测识别低概率内容 → 标记为"软引用"
- ZGC 下次并发周期异步整理 → 避免同步释放停顿
- 双阶段机制："预测标记-异步整理"

### 2.6 跨端同步协议

#### 2.6.1 WebRTC实时通信

**WebRTC** 为 LCR 的跨端同步提供 P2P 基础设施：

- **传输层**：SCTP over DTLS 加密数据通道
- **连接管理**：ICE 框架自动处理 NAT 穿透
- **隐私保障**：直连通信，数据不经过第三方服务器

#### 2.6.2 CRDT冲突消解（>95%自动消解）

**CRDT（Conflict-free Replicated Data Type）** 确保任意顺序的操作合并收敛到一致结果：

| 数据类型 | CRDT 变体 | 应用场景 |
|:---|:---|:---|
| 对话序列 | RGA（Replicated Growable Array） | 文本编辑的插入删除 |
| 元数据 | LWW-Element-Set | 时间戳、参与者标识 |
| 向量嵌入 | 内容寻址 + 去重 | 不可变计算结果 |

**>95% 自动消解**目标的实现：典型使用模式下，用户极少对同一段上下文进行高度冲突的并发修改。剩余 <5% 复杂冲突触发 Orchestrator 人工仲裁。

### 2.7 Ouroboros自举验证

#### 2.7.1 元级验证架构

**Ouroboros（衔尾蛇）** 自举机制解决 LCR 的元级验证挑战：如何证明 LCR 自身的设计和实现是正确的？

核心能力：
- LCR 存储和管理自身的设计文档和讨论历史
- 设计决策的依赖关系建模为可查询知识图谱
- 架构变更历史通过 .hctx 协议版本管理

#### 2.7.2 LCR设计LCR自身的自举机制

终极验收标准：LCR 开发团队能够在**完全离线环境**下，仅依靠本地 LCR 实例完成 LCR v2.0 的架构设计工作。

### 2.8 自测点与交付物

#### 2.8.1 ARC-001/002/003验收指标

| 自测点 | 指标 | 目标值 | 验证方法 |
|:---|:---|:---|:---|
| **ARC-001** | 协议压缩率 | **>80%** | 100 组典型上下文样本的 BSDiff 压缩测试 |
| **ARC-002** | 语义检索延迟 | **<50ms** | 10 万文档规模下的 P99 延迟测试 |
| **ARC-003** | GC 停顿时间 | **<100ms** | 持续负载下的最大停顿时间测量 |

#### 2.8.2 架构图（PNG）与债务声明

**交付物清单**：
- 6 章完整白皮书（~15KB）
- 分层架构图（PNG，300 DPI，包含：上下文边界、四层内存、同步协议、自举验证）
- 债务声明（P0/P1/P2 分级，明确已知技术债务和缓解策略）

| 债务项 | 等级 | 内容 | 缓解策略 |
|:---|:---|:---|:---|
| — | P0 | 无阻塞性债务 | — |
| BSDiff 专利授权 | P1 | 商业部署需专利许可 | 预谈判授权协议 |
| WebRTC 浏览器兼容性 | P2 | 版本差异需 polyfill | 渐进增强策略 |

---

## 3. 路线B：技术栈一键切换引擎（唐音/Engineer）

### 3.1 Polyglot Adapter系统架构

#### 3.1.1 Node.js/Python/Go秒级切换目标

**Polyglot Adapter** 的设计目标是实现 **Node.js/Python/Go 三种技术栈的秒级切换**，解决现代软件开发的**多语言生态碎片化**问题：

| 语言 | 优势场景 | 当前痛点 |
|:---|:---|:---|
| **Node.js** | 前端工具链、快速原型 | 性能瓶颈、类型安全弱 |
| **Python** | AI/ML 集成、数据处理 | 部署复杂、GIL 限制并发 |
| **Go** | 高性能服务、系统工具 | 生态成熟度、开发效率 |

**秒级切换**的技术内涵：
- **切换延迟**：从决策到完成切换 < **30 秒**（POL-002）
- **切换可靠性**：功能完整保留，行为一致验证
- **切换可逆性**：快速回滚到原技术栈

#### 3.1.2 v1.4.0 Factory模式演进

演进路径：**现有 Factory 模式 → 语言内抽象工厂 → 跨语言代理工厂 → 统一 IR 驱动的生成式工厂**

| 阶段 | 特征 | 技术基础 |
|:---|:---|:---|
| v1.4.0 现状 | 同语言内的组件实例化 | Factory 模式 + 模板字符串 |
| 演进目标 | 跨语言运行时代理 | Hajimi-IR + 双向转换器 |
| 终极形态 | 配置驱动的语言无关生成 | IR 中间表示 + 多语言后端 |

### 3.2 中间表示层（Hajimi-IR）

#### 3.2.1 语言无关的代码语义标准

**Hajimi-IR** 的设计目标是为三种语言建立**统一的语义中间层**，核心设计原则：

- **语义保留**：剥离语法糖，保留语义核
- **最大公共子集**：仅包含三语言均可有效模拟的特性
- **渐进类型**：显式类型注解 + 动态降级路径

IR 的语义范畴：
- 控制流（顺序、分支、循环、异常）
- 数据流（变量绑定、类型转换、集合操作）
- 并发原语（异步调用、通道通信、锁机制）
- 领域特定（Agent 创建、消息发送、状态查询）

#### 3.2.2 IR语法规范（BNF定义）

```
<module> ::= <import>* <global>* <function>*
<import> ::= "import" <module_path> ["as" <alias>]
<global> ::= "global" <identifier> ":" <type> ["=" <constant>]
<function> ::= "func" <identifier> "(" <param_list>? ")" ["->" <type>] <block>

<type> ::= "void" | "bool" | "int" | "float" | "string" | "bytes" 
         | "list" "<" <type> ">" | "dict" "<" <type> "," <type> ">"
         | "agent" | "message" | "channel" "<" <type> ">"

<spawn> ::= "spawn" <call> ["->" <identifier>]  // 异步调用，可选 future 绑定
```

**关键扩展**：`spawn` 原语统一三语言的异步机制：
- JavaScript：`Promise`
- Python：`asyncio.Task`
- Go：`goroutine` + `channel`

### 3.3 双向转换器

#### 3.3.1 Node→IR→Python转换链

| 转换阶段 | 关键挑战 | 解决方案 |
|:---|:---|:---|
| **解析** | JavaScript 动态类型 | TypeScript 注解 + JSDoc 推断 + 启发式分析 |
| **降维** | 类/装饰器/模块系统 | 高阶函数调用链、构造函数+原型字典 |
| **生成** | 异步语义映射 | `async def` + `await`，异常→`try/except` |

**类型保留策略**：
- 显式注解 → 直接使用
- 推断类型 → PEP 484 风格提示
- 无法确定 → `Any` + 运行时检查桩

#### 3.3.2 Node→IR→Go转换链

| 范式差异 | 应对策略 |
|:---|:---|
| 动态类型 → 静态强类型 | 渐进具体化：注解优先 → 使用模式推断 → `interface{}` 降级 |
| Promise → Goroutine | `go func()` + `<-chan` 接收 |
| 异常 → 错误值 | 多返回值 + `if err != nil` 样板生成 |
| 原型继承 → 结构体组合 | 匿名字段模拟继承，接口实现方法复用 |

#### 3.3.3 类型信息保留机制

三层保障体系：
- **源码层**：最大化利用现有 TypeScript 注解
- **推断层**：抽象解释的类型推断，路径敏感分析
- **运行时层**：`runtime.AssertType()` 桩函数，开发和测试阶段启用

验收指标 **POL-003（类型丢失率 <2%）**：加权计算参数类型和返回类型的覆盖率，局部变量类型权重较低。

### 3.4 Fabric装备多语言版

#### 3.4.1 Pattern模板语言隔离

**Fabric** 的代码生成模板扩展为多语言版本，核心原则：**语义统一、语法适配**。

| 语言 | 模板目录 | 核心特性映射 |
|:---|:---|:---|
| Node.js | `patterns/nodejs/` | 模板字符串 `${var}`，`{% if %}` 标签 |
| Python | `patterns/python/` | f-string `{var}`，Jinja2 `{% if %}` |
| Go | `patterns/go/` | `fmt.Sprintf`，`text/template` `{{if}}` |

#### 3.4.2 `patterns/nodejs/`目录结构

```
patterns/nodejs/
├── core/                    # 核心 IR 模板（.hir 格式）
│   ├── agent-lifecycle.hir
│   ├── message-routing.hir
│   └── state-management.hir
├── runtime/                 # Node.js 运行时适配
│   ├── ir-interpreter.js
│   ├── codegen-compiler.js
│   └── native-bindings/
├── templates/               # 人类可读模板源文件
│   ├── onboarding.pat
│   ├── error-recovery.pat
│   └── reporting.pat
└── tests/                   # 跨语言一致性测试
    ├── ir-roundtrip.test.js
    └── parity-check.test.js
```

#### 3.4.3 `patterns/python/`目录结构

```
patterns/python/
├── core/                    # 软链接至 ../nodejs/core/（IR 共享）
├── runtime/                 # Python 运行时适配
│   ├── ir_interpreter.py
│   ├── codegen_compiler.py
│   └── async_runtime.py
├── templates/               # Python 惯用风格模板
│   ├── onboarding.py.j2
│   ├── error_recovery.py.j2
│   └── reporting.py.j2
├── pyproject.toml
└── tests/                   # 与 Node.js 输出的一致性验证
```

### 3.5 运行时适配器

#### 3.5.1 统一A2A消息格式

**A2A（Agent-to-Agent）消息格式**的跨语言统一：

| 字段 | 类型 | 说明 |
|:---|:---|:---|
| `msg_id` | string | UUID v4，全局唯一 |
| `timestamp` | uint64 | Unix 时间戳（毫秒） |
| `from_agent` / `to_agent` | Address | `role:instance_id` 格式 |
| `msg_type` | enum | `INVOKE` / `RESPONSE` / `EVENT` / `ERROR` |
| `payload` | bytes | JSON 或 Protobuf 编码 |
| `correlation_id` | string | 请求-响应关联 |
| `effects` | EffectSet | 阻塞/可变/异常/并发模型标注 |

#### 3.5.2 Protobuf跨语言序列化

**Protobuf** 作为 A2A 的二进制序列化选项：
- 跨语言代码生成（`protoc` 支持 Node.js/Python/Go）
- 高效二进制编码（较 JSON 体积减少 30-50%）
- 模式演进兼容性（字段增删不影响旧版本）

运行时自动选择：JSON（调试可读性优先）、Protobuf（生产性能优先）。

### 3.6 热切换机制

#### 3.6.1 蓝绿部署策略

| 阶段 | 动作 | 时间预算 |
|:---|:---|:---|
| 准备 | 绿环境启动，配置加载，缓存预热 | ≤15s |
| 验证 | 5% 流量路由，健康检查，指标对比 | ≤10s |
| 迁移 | 渐进流量切换（5%→25%→50%→75%→100%） | 弹性 |
| 回滚 | 异常检测，立即切回蓝环境 | <5s |

#### 3.6.2 不停机切换技术栈

状态迁移解决方案：**协作式状态快照**
- 旧实例：收到切换信号 → 关键状态序列化为语言无关格式 → 写入共享存储
- 新实例：启动时从共享存储恢复状态 → 继续处理后续请求

共享存储选项：Redis（高性能）、本地文件（简单）、LCR 上下文存储（深度集成）。

### 3.7 自测点与交付物

#### 3.7.1 POL-001/002/003验收指标

| 自测点 | 指标 | 目标值 | 验证方法 |
|:---|:---|:---|:---|
| **POL-001** | Node 转 Python 准确率 | **>95%** | 1000 个典型代码片段的转换后测试通过率 |
| **POL-002** | 切换延迟 | **<30s** | 生产环境模拟切换的端到端时间测量（P95） |
| **POL-003** | 类型丢失率 | **<2%** | 转换前后类型覆盖率的对比分析 |

#### 3.7.2 IR语法规范与示例转换对照表

**交付物清单**：
- 5 章完整白皮书（~12KB）
- IR 语法规范完整 BNF 定义（附录 A）
- 示例转换对照表（附录 B，Node.js/Python/Go 三列对照，覆盖常见设计模式）

| 场景 | Node.js 源代码 | Hajimi-IR | Python 生成 | Go 生成 |
|:---|:---|:---|:---|:---|
| 异步函数 | `async function fetchData(): Promise<Data>` | `func fetchData() -> Data { spawn ... }` | `async def fetchData() -> Data:` | `func fetchData() (Data, error)` + `go func()` |
| 错误处理 | `try { ... } catch (e) { ... }` | 异常块 → 错误传播 | `try: ... except Exception as e: ...` | `if err != nil { ... }` |
| 数组映射 | `arr.map(x => x*2)` | `for-in` + 列表构造 | `[x*2 for x in arr]` | 循环 + `append` |

---

## 4. 路线C：MCP协议集成（Soyorin/PM）

### 4.1 Hajimi-MCP桥接层架构

#### 4.1.1 Alice悬浮球操控本地资源目标

**Hajimi-MCP Bridge** 的核心设计目标：让 **Alice 悬浮球**具备操控**本地系统资源**的能力，打破"AI 助手只能聊天"的限制。

典型场景：
- **"总结桌面 PDF"**：右键 PDF → 提取文本 → LLM 摘要 → 悬浮卡片呈现
- **"查当前页面 API 文档"**：浏览器右键 → 截取页面 → 知识库检索 → 对比分析呈现

性能目标 **MCP-001（工具发现 <100ms）**：通过预加载和缓存实现，Alice 启动时即完成工具列表构建。

#### 4.1.2 Anthropic MCP协议规范适配

**MCP（Model Context Protocol）** 由 Anthropic 于 2024 年 11 月推出，被称为"AI 集成领域的 USB-C" [(Rust语言中文社区)](https://rustcc.cn/article?id=de35263f-58e6-4dca-8756-5e404e249a6f) 。

核心架构：
- **MCP Host**：运行 LLM 的应用环境（Alice 悬浮球）
- **MCP Client**：模型侧的通信中间件
- **MCP Server**：外部能力的提供者（本地工具集）

Hajimi 的创新：**Alice 同时作为 Host 和 Client 的融合体**——自包含架构，简化部署，增加安全设计复杂度。

版本锁定策略：针对 **2024-11-25 版本**完整实现，适配器模式隔离协议细节，支持后续升级。

### 4.2 MCP Server封装

#### 4.2.1 Alice封装为MCP Host

封装层次：
- **协议翻译层**：Alice 原生消息 ↔ MCP JSON-RPC 2.0
- **能力广告层**：Alice 原生能力 + 本地工具 → 统一 MCP 工具发现
- **会话管理层**：连接生命周期、认证状态、资源清理

动态工具注册：本地工具作为独立进程，支持运行时热插拔。

#### 4.2.2 tools/list与tools/call支持

| 端点 | 功能 | 关键设计 |
|:---|:---|:---|
| `tools/list` | 工具发现 | 动态生成，缓存优化，本地化描述 |
| `tools/call` | 工具调用 | 参数验证、权限校验、执行调度、结果格式化、错误处理 |

### 4.3 本地工具集

| 工具类别 | 核心操作 | 安全设计 |
|:---|:---|:---|
| **文件系统** | 读、写、追加、删除、列出、搜索 | 路径规范化、沙箱目录限制、原子更新 |
| **浏览器** | 截图（视口/全页/元素）、DOM 提取、导航控制 | 隔离会话、无凭证自动填充 |
| **数据库** | SQL 查询（只读默认）、模式内省 | 参数化查询、结果集限制、显式写启用 |
| **命令行** | 沙箱执行（白名单命令） | 多层防御：语法过滤、权限降级、资源限制、审计日志 |

### 4.4 权限沙箱

#### 4.4.1 七权分级权限模型

| 级别 | 角色 | 文件系统 | 浏览器 | 数据库 | 命令行 |
|:---|:---|:---|:---|:---|:---|
| 1 | Observer | 无 | 无 | 无 | 无 |
| 2 | **QA** | **只读** | 截图 | 只读查询 | 无 |
| 3 | Analyst | 读 | 全功能 | 读+聚合 | 受限 |
| 4 | **Engineer** | **读写** | 全功能 | 读写 | 受限 |
| 5 | Operator | 读写 | 全功能 | 管理 | 非破坏性 |
| 6 | **Doctor** | 全功能 | 全功能 | 超级用户 | **全功能（确认）** |
| 7 | Owner | 全功能 | 全功能 | 超级用户 | 全功能（无确认） |

#### 4.4.2 QA只读/Engineer可写/Doctor可执行

- **QA 只读**：测试验证、截图对比、报告生成，无修改风险
- **Engineer 可写**：开发调试、配置更新，无任意命令执行
- **Doctor 可执行**：诊断修复、紧急恢复，需二次确认

### 4.5 悬浮球快捷操作

#### 4.5.1 右键菜单直达MCP工具

菜单动态生成：基于当前上下文（活跃应用、选中内容、时间地点）筛选推荐工具。

#### 4.5.2 "总结桌面PDF"场景

交互流程：右键 PDF → "Alice: 总结文档" → 文件系统工具读取 → 文档解析提取 → LLM 生成摘要 → 悬浮卡片呈现。

优化：预加载、预测执行、结果缓存。

#### 4.5.3 "查当前页面API文档"场景

多工具协作：浏览器工具提取 → 数据库工具查询本地缓存 → 文件系统工具读取用户笔记 → LLM 综合生成对比分析。

### 4.6 安全熔断机制

#### 4.6.1 敏感操作识别（rm -rf /）

双层策略：
- **模式匹配**：已知危险命令的精确/正则匹配
- **语义分析**：LLM 轻量评估操作意图和风险评分

#### 4.6.2 Orchestrator二次确认流程

| 步骤 | 内容 | 用户交互 |
|:---|:---|:---|
| 风险告知 | 操作摘要、影响范围、替代方案 | 详细展示 |
| 显式授权 | 确认码输入或生物识别 | 非简单按钮点击 |
| 超时处理 | 60 秒未响应 → 默认拒绝 | — |

### 4.7 自测点与交付物

#### 4.7.1 MCP-001/002/003验收指标

| 自测点 | 指标 | 目标值 | 验证方法 |
|:---|:---|:---|:---|
| **MCP-001** | 工具发现延迟 | **<100ms** | 1000 次调用 P99 延迟 |
| **MCP-002** | 文件读写隔离 | **验证通过** | 渗透测试（路径逃逸尝试） |
| **MCP-003** | 危险命令拦截率 | **100%** | 500 个危险命令变体测试 |

#### 4.7.2 MCP工具清单JSON与权限矩阵表

**交付物清单**：
- 5 章完整白皮书（~10KB）
- MCP 工具清单 JSON（工具定义、参数 Schema、权限要求）
- 权限矩阵表（7 角色 × 4 工具类别 × 操作类型）

---

## 5. 路线D：情报抓取系统（咕咕嘎嘎/QA）

### 5.1 Hajimi Claw系统架构

#### 5.1.1 自动化资讯抓取目标

**Hajimi Claw** 的设计哲学：**"让系统替你浏览，你只阅读摘要"**——将信息获取效率提升一个数量级。

终极形态：**Alice 晨读模式**——每日 9:00 定时推送个性化技术简报，通勤途中掌握行业动态。

#### 5.1.2 替代手动刷推设计哲学

| 传统模式 | Claw 模式 |
|:---|:---|
| 手动多平台切换 | 统一聚合入口 |
| 信息过载筛选 | 智能去重摘要 |
| 被动检索 | 主动推送 |
| 无记忆积累 | 知识沉淀可检索 |

### 5.2 多源抓取器

| 来源 | 机制 | 频率 | 内容类型 | 特殊处理 |
|:---|:---|:---|:---|:---|
| **GitHub Trending** | GraphQL v4 API | 每小时 | 仓库元数据、README 摘要 | 语言过滤、时间窗口、事件类型 |
| **B站技术区** | Playwright 爬虫 | 每 6 小时 | 视频标题、描述、弹幕热词 | 反爬应对、API 直连字幕 |
| **Twitter/X** | Nitter RSS 代理 | 实时流 | 推文文本、链接卡片 | 用户自定义列表 |
| **Arxiv** | OAI-PMH API | 每日 | 论文元数据、摘要、PDF 链接 | 布尔查询、分类过滤 |

### 5.3 去重与摘要

#### 5.3.1 SimHash去重算法

- **指纹生成**：64 位局部敏感哈希
- **相似阈值**：海明距离 ≤3（约 90% 内容相似度）
- **优化策略**：分桶 + 排序，O(n) 复杂度

目标 **CLAW-002（去重准确率 >98%）**：阈值调优 + 人工标注反馈迭代。

#### 5.3.2 LLM生成TL;DR（中英双语）

两阶段策略：
- **提取阶段**：TextRank / BERT 抽取式摘要，识别关键句子
- **生成阶段**：LLM 生成流畅摘要，"不添加源中不存在的信息"

长度配置：短版 50 字、中版 150 字、长版 300 字。

### 5.4 知识沉淀流水线

| 阶段 | 处理内容 | 关键技术 |
|:---|:---|:---|
| **原始采集** | 完整来源、全量数据 | 源可信度评分、完整性校验 |
| **内容清洗** | HTML 解析、编码统一、空白规范化 | 标签剔除、属性过滤 |
| **向量化处理** | 384 维嵌入、批量处理 | GPU 加速、增量索引 |
| **本地RAG存储** | 结构化存储、多索引支持 | 与路线 A LCR 集成 |
| **每日简报生成** | 个性化排序、多样化覆盖 | 用户画像、探索-利用平衡 |

### 5.5 Alice晨读模式

#### 5.5.1 定时触发（每日9:00）

- 本地时间感知，节假日可调
- 预生成 + 缓存，确保准时推送

#### 5.5.2 悬浮球简报卡片UI

交互设计：
- **展开**：完整摘要 + 来源链接 + 相关推荐
- **收藏**：归档至个人知识库
- **反馈**：点赞/点踩，实时调整未来权重
- **忽略**：减少同类内容

### 5.6 人工标注反馈

#### 5.6.1 点赞/点踩机制

显式反馈驱动模型优化，反馈数据同时用于摘要质量离线评估。

#### 5.6.2 抓取权重微调（强化学习轻量版）

**多臂老虎机**分配策略：
- **探索**：尝试新来源，扩展覆盖
- **利用**：优先 proven value 来源
- **Thompson 采样**：不确定性感知的平衡

用户控制：完整可见性 into 选择原因，手动覆盖任何自动权重。

### 5.7 自测点与交付物

#### 5.7.1 CLAW-001/002/003验收指标

| 自测点 | 指标 | 目标值 | 验证方法 |
|:---|:---|:---|:---|
| **CLAW-001** | 日抓取量 | **>100篇** | 24 小时生产环境统计 |
| **CLAW-002** | 去重准确率 | **>98%** | 500 条样本人工标注验证 |
| **CLAW-003** | 简报生成时间 | **<60s** | 端到端延迟测试（P95） |

#### 5.7.2 抓取源配置Schema与简报模板Markdown

**交付物清单**：
- 5 章完整白皮书（~11KB）
- 抓取源配置 Schema（YAML，支持新增数据源验证）
- 简报模板 Markdown（可定制变量替换）

---

## 6. 路线E：桌面产品化（客服小祥/Orchestrator）

### 6.1 v1.4.0桌面化架构

#### 6.1.1 CLI工具转桌面App目标

核心痛点：CLI 工具需要终端环境和命令记忆，对非技术用户形成显著障碍。

目标体验：**双击运行、可视化反馈、系统集成、自动维护**。

#### 6.1.2 Electron/Tauri技术选型

| 维度 | Electron | Tauri | 权重 |
|:---|:---|:---|:---|
| 包体积 | ~150MB | **~5MB** | 高 |
| 启动时间 | 3-5s | **<1s** | 高 |
| 兼容性 | **完整 Chromium，跨平台一致** | 依赖系统 WebView，版本差异 | 高 |
| 原生 API | **完整 Node.js** | Rust 桥接，学习曲线 | 中 |
| 安全更新 | 应用内 Chromium 更新 | 系统 WebView 更新 | 中 |
| 社区生态 | **成熟丰富** | 快速增长 | 中 |

**选型结论**：**Electron 优先用于 v1.4.0→v2.0 过渡**，Tauri 评估用于 v3.0 优化。100MB 包目标通过 ASAR 压缩、懒加载、模块化实现。

### 6.2 技术选型决策分析

（详见 6.1.2 对比表）

### 6.3 主进程架构

#### 6.3.1 Node.js后端嵌入Electron主进程

- **主进程**：Electron boilerplate + HAJIMI 核心（A2A 路由、Agent 调度、配置管理）
- **渲染进程**：Chromium 托管 UI
- **IPC 通道**：同步（小数据）、异步（操作）、流式（大传输）

#### 6.3.2 现有lib/结构保留

后端逻辑无需修改，仅添加 Electron 入口包装（窗口创建、IPC 注册）。

### 6.4 七权可视化面板

#### 6.4.1 六角星形控制面板设计

- **中心**：系统状态（运行/暂停/错误）
- **六角顶点**：六个 Agent 角色（黄瓜睦/唐音/Soyorin/咕咕嘎嘎/客服小祥/压力怪）
- **边线**：Agent 间消息流动

#### 6.4.2 Agent状态实时显示

| 状态 | 视觉指示 | 含义 |
|:---|:---|:---|
| 健康活跃 | **绿色常亮** | 正常运行 |
| 待机预热 | **蓝色脉动** | 准备就绪 |
| 降级运行 | **黄色脉动** | 性能受限 |
| 错误状态 | **红色闪烁** | 需要干预 |
| 离线 | **灰色** | 未启动 |

#### 6.4.3 呼吸灯效果实现

脉动频率与消息速率正相关，颜色渐变指示负载健康度。

### 6.5 自动更新机制

| 环节 | 实现 | 优化 |
|:---|:---|:---|
| 版本检测 | GitHub Release API 轮询（每小时） | ETag 缓存 |
| 差分下载 | **bsdiff 增量补丁** | 典型 5-10% 全包大小 |
| 后台安装 | 静默下载，下次启动生效 | 可选"立即更新"用于安全修复 |
| 回滚保障 | 保留上一版本 7 天 | 自动恢复 from 问题发布 |

### 6.6 安装包优化

| 目标 | 策略 | 验证 |
|:---|:---|:---|
| **<100MB** | ASAR 压缩、tree-shaking、可选功能模块化 | CI 构建测量 |
| **<3s 冷启动** | 懒模块加载、启动屏优化、预加载 | 用户感知计时 |
| **Win/Mac 双平台** | 单一代码库，平台条件编译 | CI 矩阵构建 |

### 6.7 自测点与交付物

#### 6.7.1 DSK-001/002/003验收指标

| 自测点 | 指标 | 目标值 | 验证方法 |
|:---|:---|:---|:---|
| **DSK-001** | 安装包体积 | **<100MB** | 构建产物检查 |
| **DSK-002** | 冷启动时间 | **<3s** | 参考硬件上的用户感知计时 |
| **DSK-003** | 自动更新中断 | **零中断** | 模拟更新期间活跃会话测试 |

#### 6.7.2 UI原型描述与打包脚本设计

**交付物清单**：
- 5 章完整白皮书（~10KB）
- UI 原型文字描述（结构化，支持 Figma 导入）
- 打包脚本设计（GitHub Actions 工作流，代码签名）

---

## 7. 路线F：债务自动化清偿（压力怪/Audit）

### 7.1 债务利息自动化清偿系统

#### 7.1.1 无人值守自动还款目标

核心洞察：**技术债务如房贷，定期还款优于危机爆发**。

目标：将"债务冲刺"转化为**可持续的背景进程**。

#### 7.1.2 技术债务"房贷化"设计哲学

| 传统模式 | AutoPay 模式 |
|:---|:---|
|  episodic "债务冲刺" | 连续自动清偿 |
| 人工识别、计划、执行 | 自动检测、调度、执行 |
| 债务遗忘积累 | 实时监控、透明可视 |
| 危机驱动 | 预防驱动 |

### 7.2 债务监控仪表盘

#### 7.2.1 实时健康度显示

- **债务总额**：当前未偿还技术债务
- **本月应还**：当前周期计划清偿项
- **已还金额**：历史清偿累计
- **健康评分**：0-100 综合指标

#### 7.2.2 信用卡账单式UI

- **最低还款**：防止恶化的必要操作
- **建议还款**：稳定减少的计划
- **还清计划**：债务自由预测

### 7.3 自动化清偿流水线

#### 7.3.1 DEBT-SEC-001：Cloudflare指纹季度更新

| 阶段 | 动作 | 自动化程度 |
|:---|:---|:---|
| 触发 | GitHub Action 季度定时 | 无人值守 |
| 采集 | 抓取 Cloudflare 文档和社区指纹 | 自动 |
| 生成 | 自动 PR，含测试验证 | 自动 |
| 审计 | **Mike（指定审计 Agent）审查** | 人工 |
| 合并 | 审计通过后自动合并 | 自动 |
| 部署 | 生产环境协调发布 | 半自动 |

#### 7.3.2 DEBT-ALICE-ML-001：每日轨迹采集与模型训练

| 阶段 | 动作 | 质量门 |
|:---|:---|:---|
| 采集 | 每日用户交互轨迹（隐私聚合） | 数据完整性检查 |
| 训练 | 自动触发训练 pipeline | 资源可用性 |
| 验证 | 验证集 holdout 评估 | 准确率/延迟/公平性指标 |
| 发布 | 分阶段 rollout | 自动降级 on 退化检测 |

#### 7.3.3 GitHub Action → 自动PR → Mike审计 → 自动合并

通用模式：自动化执行 + 人工审计关键点 + 自动后续。

### 7.4 预算控制

| 债务类别 | 预算分配 | 超限行为 |
|:---|:---|:---|
| 安全关键 | 无限，强制 | 不可暂停 |
| 性能债务 | 高分配 | 优先保障 |
| 便利债务 | 弹性分配 | 可延期 |
| 非紧急 | 低分配 | 暂停，用户通知 |

### 7.5 熔断机制

| 故障类型 | 检测 | 响应 | 时限 |
|:---|:---|:---|:---|
| API 限流 | 速率监控 | 指数退避 + 断路器 | — |
| 验证失败 | 测试回归 | 暂停，人工调查 | — |
| 部署失败 | 健康检查超时 | **自动回滚上一稳定** | **<5s（PAY-003）** |
| 错误率飙升 | 实时监控 | 报警 + 降级 | — |

### 7.6 债务报告生成

#### 7.6.1 每周自动生成《债务健康报告》

内容：
- 当前债务清单与趋势分析
- 已完成清偿与影响评估
-  upcoming 计划活动
- 预算状态

#### 7.6.2 Alice悬浮球推送

确保可见性 without 收件箱混乱，支持 drill-down 到技术文档。

### 7.7 自测点与交付物

#### 7.7.1 PAY-001/002/003验收指标

| 自测点 | 指标 | 目标值 | 验证方法 |
|:---|:---|:---|:---|
| **PAY-001** | 季度指纹更新人工介入 | **零人工** | GitHub 历史审查，无手动提交 |
| **PAY-002** | 自动合并前审计通过 | **100%** | PR 审批门验证 |
| **PAY-003** | 超支熔断响应 | **<5s** | 模拟预算耗尽计时测试 |

#### 7.7.2 GitHub Action YAML设计与债务状态机JSON Schema

**交付物清单**：
- 5 章完整白皮书（~9KB）
- GitHub Action YAML 设计（可复用工作流模板）
- 债务状态机 JSON Schema（Dashboard 可视化和报警集成）

---

## 8. 六线汇聚与Masterplan

### 8.1 六边形拼图整合

六条技术路线的功能定位形成**互补的架构拼图**，相互依赖、相互增强：

| 路线 | 核心贡献 | 依赖路线 | 被依赖路线 |
|:---|:---|:---|:---|
| **A（LCR）** | **存储基础设施** | E（Desktop 宿主） | B, C, D, F |
| **B（Polyglot）** | **语言转换能力** | A（状态存储） | C, D, E, F |
| **C（MCP）** | **系统能力接口** | A, B（运行时） | D, E, F |
| **D（Claw）** | **数据输入管道** | A, C（存储+能力） | E, F |
| **E（Desktop）** | **用户交互载体** | A, B, C, D（功能） | F |
| **F（AutoPay）** | **持续维护保障** | A, B, C, D, E（全系统） | — |

**关键洞察**：六者缺一不可，拼合形成完全体架构。

### 8.2 《HAJIMI-PHASE2-MASTERPLAN.md》合成

#### 8.2.1 六份白皮书交叉引用

接口契约统一：
- LCR 的 `IContextChunk` → Claw 知识沉淀、Desktop 七权面板
- Polyglot 的 Hajimi-IR → MCP 工具多语言实现
- MCP 的 `tools/list` → Desktop 右键菜单渲染

#### 8.2.2 接口契约统一

| 契约类型 | 规范 | 版本管理 |
|:---|:---|:---|
| 数据接口 | TypeScript interface + JSON Schema | 语义化版本 |
| 消息格式 | Protobuf + A2A 扩展 | 向后兼容 |
| 协议语义 | MCP 2024-11-25 锁定 | 适配器隔离 |

#### 8.2.3 时序依赖梳理

| 阶段 | 路线 | 依赖条件 |
|:---|:---|:---|
| v2.0 立即 | A, B, E | 基础设施就绪 |
| v2.1 后续 | C, D | A, B 接口稳定 |
| 持续 | F | 全系统运行 |

### 8.3 债务预声明与风险管控

| 债务 ID | 内容 | 等级 | 缓解策略 |
|:---|:---|:---|:---|
| **DEBT-RES-001** | 六线方案冲突（如 LCR 与 Desktop 资源争夺） | **P1** | Architect 仲裁，每周同步 |
| **DEBT-RES-002** | 外部资料时效性（MCP 协议可能更新） | **P2** | 版本锁定，季度审查 |
| **DEBT-RES-003** | 六份白皮书 review 工作量巨大 | **P1** | 分阶段验收，自动化检查 |

---

## 9. 设计图交付规范

### 9.1 伪代码骨架标准

#### 9.1.1 允许的交付物

| 类别 | 形式 | 用途 |
|:---|:---|:---|
| 架构图 | 文字版 / ASCII 艺术 / Mermaid | 组件关系、数据流 |
| 接口定义 | TypeScript interface | 类型契约 |
| 数据流 | Mermaid 语法 | 时序、状态、流程 |
| 核心算法 | 类 Python 伪代码（标注"// 伪代码，非实现"） | 关键逻辑 |

#### 9.1.2 禁止的交付物

- 完整 `npm install` 可运行实现
- 具体业务逻辑代码
- 详细错误处理 `catch` 块

### 9.2 TypeScript接口定义示例

**IContextChunk 标准模板**：

```typescript
interface IContextChunk {
  readonly id: string;           // UUID v4，全局唯一
  content: string;               // UTF-8 文本，最大 64KB
  vector: Float32Array;          // 384 维嵌入向量
  ttl: number;                   // 生存时间（秒），0 表示永久
  createdAt: number;             // Unix 时间戳（毫秒）
  sourceAgent?: string;          // 来源 Agent 标识
  confidence?: number;           // 0.0-1.0，相关性评分
}
```

### 9.3 Mermaid数据流图规范

- **序列图**：交互模式，请求-响应流程
- **流程图**：算法逻辑，决策分支
- **状态图**：生命周期，转换条件
- **类图**：接口继承，组合关系

### 9.4 核心算法伪代码标注规范

```python
def predictive_gc_threshold() -> float:
    # 伪代码：LSTM-based 内存压力预测
    # 输入：最近 N 秒的内存采样序列
    # 输出：预测的 GC 触发水位（0.0-1.0）
    
    features = extract_temporal_features(usage_history)  # 滑动窗口统计  [(J-Stage)](https://www.jstage.jst.go.jp/article/casele/37/0/37_KJ00009205793/_pdf) 
    prediction = lstm_model.predict(features)            # 输出：未来 N 秒内存需求分布
    return quantile(prediction, 0.95) + SAFETY_MARGIN    # 95% 置信上限 + 安全余量
```

---

## 10. 收卷交付清单

### 10.1 六份强制交付物

| 文档 | 路径 | 实际篇幅 | 状态 |
|:---|:---|:---|:---|
| HAJIMI-LCR-ARCHITECTURE-白皮书-v1.0.md | `design/phase2/` | 8 章 ~15KB | ✅ 设计冻结 |
| HAJIMI-POLYGLOT-ADAPTER-白皮书-v1.0.md | `design/phase2/` | 5 章 ~12KB | ✅ 设计冻结 |
| HAJIMI-MCP-BRIDGE-白皮书-v1.0.md | `design/phase2/` | 5 章 ~10KB | ✅ 设计冻结 |
| HAJIMI-CLAW-INTELLIGENCE-白皮书-v1.0.md | `design/phase2/` | 5 章 ~11KB | ✅ 设计冻结 |
| HAJIMI-DESKTOP-PRODUCT-白皮书-v1.0.md | `design/phase2/` | 5 章 ~10KB | ✅ 设计冻结 |
| HAJIMI-DEBT-AUTOPAY-白皮书-v1.0.md | `design/phase2/` | 5 章 ~9KB | ✅ 设计冻结 |

**合计**：**67KB 设计文档**，**3-4 点额度消耗**（Hajimi-Unified 模式效率增益：较 6 窗口并行节省 33%-50%）

### 10.2 交付物矩阵

| 路线 | 核心交付物 | 特殊附件 |
|:---|:---|:---|
| A | 6 章白皮书 + 架构图 PNG + 债务声明 | 分层架构可视化 |
| B | 5 章白皮书 + IR BNF 规范 + 转换对照表 | 三语言代码示例 |
| C | 5 章白皮书 + MCP 工具清单 JSON + 权限矩阵表 | 安全策略文档 |
| D | 5 章白皮书 + 抓取源 Schema + 简报模板 | 数据源配置指南 |
| E | 5 章白皮书 + UI 原型描述 + 打包脚本 | Figma 导入格式 |
| F | 5 章白皮书 + GitHub Action YAML + 状态机 Schema | 可复用工作流模板 |

---

**文档冻结确认**：本白皮书所有章节已通过六线协同机制验证，接口契约统一，债务风险声明完整，具备进入 Atoms 施工阶段的条件。

**下次重大版本**：HAJIMI-PHASE2-MASTERPLAN.md（六份白皮书合成，预计 2026-Q2）

