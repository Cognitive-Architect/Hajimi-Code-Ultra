.* FILE: delivery/v0.9.1/Hajimi-Diff-Format-Spec-v0.9.1.md */
# Hajimi-Diff Format Spec v0.9.1 (Freeze Draft)

## 1. Magic & Version
- Magic: `HAJI` (4 bytes)
- Version: 0.9

## 2. Fixed Sizes
- Header: 64 bytes
- Index Entry: 26 bytes (fixed)
- Footer: 48 bytes

## 3. Integrity Chain
- L1: SHA-256(file)
- L2: XXH64(index_table)
- L3: BLAKE3-256(file_without_footer)

## 4. BNF (摘要)
Header := Magic(4) VersionMajor(1) VersionMinor(1) Flags(1) IndexCount(u32le) ...
IndexEntry := DataOffset(u64le) DataLen(u32le) UncompressedLen(u32le) Flags(u16le) ChunkXXH64(8)
Footer := FileBLAKE3(32) IndexXXH64(8) Reserved(8)

## 5. 债务声明
- DEBT-COMP-001: BLAKE3-256当前为fallback实现

/* FILE: scripts/generate-golden-vector.js */
// DEBT-B01-001: 黄金向量payload当前为固定字符串"Hello, Hajimi!"，若需真随机性需改用crypto.randomBytes
// DEBT-GOLDEN: 仅生成最小样例，未覆盖完整压缩场景和复杂数据，P1级别
'use strict';
const fs = require('fs');
const path = require('path');
const crypto = require('crypto');
const { xxh64 } = require('../src/hash/xxh64');
const { blake3_256 } = require('../src/hash/blake3_256');
function u64leWrite(buf, off, v) {
  buf.writeBigUInt64LE(BigInt(v), off);
}
function buildZstdRawFrame(payload) {
  // zstd frame: magic(4) + frameHeaderDescriptor(1) + frameContentSize(1) + blockHeader(3) + rawPayload
  // 选型：single segment=1 + fcs=1byte + no dict + no checksum
  const magic = Buffer.from([0x28, 0xB5, 0x2F, 0xFD]);
  const fhd = Buffer.from([0x20]); // single-segment=1, fcsFlag=0, dict=0, checksum=0
  const fcs = Buffer.from([payload.length & 0xFF]);
  // block header: last=1, type=raw(0b00), size=payload.length
  const bhVal = (payload.length << 3) | 0x01;
  const bh = Buffer.from([bhVal & 0xFF, (bhVal >> 8) & 0xFF, (bhVal >> 16) & 0xFF]);
  return Buffer.concat([magic, fhd, fcs, bh, payload]);
}
function buildMinimalHdiff() {
  const raw = Buffer.from('Hello, Hajimi!', 'utf8'); // 14 bytes
  const zstdFrame = buildZstdRawFrame(raw);
  const HEADER_LEN = 64;
  const INDEX_ENTRY_LEN = 26;
  const FOOTER_LEN = 48;
  const indexCount = 1;
  const indexOffset = HEADER_LEN;
  const indexLength = INDEX_ENTRY_LEN * indexCount;
  const dataOffset = indexOffset + indexLength;
  const dataLength = zstdFrame.length;
  const footerOffset = dataOffset + dataLength;
  // Header (64B) - 按冻结规格字段布局
  const header = Buffer.alloc(HEADER_LEN, 0);
  header.write('HAJI', 0, 4, 'ascii');
  header.writeUInt8(0x00, 0x04); // major
  header.writeUInt8(0x09, 0x05); // minor
  header.writeUInt8(0x00, 0x06); // flags
  header.writeUInt32LE(indexCount, 0x07);
  u64leWrite(header, 0x0B, indexOffset);
  u64leWrite(header, 0x13, indexLength);
  u64leWrite(header, 0x1B, dataOffset);
  u64leWrite(header, 0x23, dataLength);
  u64leWrite(header, 0x2B, footerOffset);
  // 0x33..0x3F reserved+padding already zeroed
  // Index Entry (26B)
  const indexEntry = Buffer.alloc(INDEX_ENTRY_LEN, 0);
  u64leWrite(indexEntry, 0x00, dataOffset);             // absolute file offset
  indexEntry.writeUInt32LE(dataLength, 0x08);            // compressed length
  indexEntry.writeUInt32LE(raw.length, 0x0C);            // uncompressed length
  // Flags: bits[15:14]=Importance, bits[13:2]=DictID, bits[1:0]=0
  const importanceUser = 0b10;
  const dictId = 0; // minimal sample no dict
  const flags = (importanceUser << 14) | (dictId << 2);
  indexEntry.writeUInt16LE(flags & 0xFFFF, 0x10);
  const chunkXxh64 = xxh64(zstdFrame, 0n);               // 输入：压缩帧字节（文件真实内容）
  chunkXxh64.copy(indexEntry, 0x12);
  // File body (no footer)
  const preFooter = Buffer.concat([header, indexEntry, zstdFrame]);
  // Footer (48B): blake3_256(preFooter) + index_xxh64(indexTable) + reserved(8)
  const footer = Buffer.alloc(FOOTER_LEN, 0);
  const fileBlake3 = blake3_256(preFooter);
  fileBlake3.copy(footer, 0x00);
  const indexTableBytes = Buffer.concat([indexEntry]);
  const indexXxh64 = xxh64(indexTableBytes, 0n);
  indexXxh64.copy(footer, 0x20);
  const fullFile = Buffer.concat)[preFooter, footer]);
  const fileSha256 = crypto.createHash('sha256').update(fullFile).digest('hex');
  const golden = {
    version: '0.9.1',
    file_size: fullFile.length,
    hash_algo: 'blake3-256', // 我们现在使用自己实现的BLAKE3-256
    file_sha256: fileSha256,
    file_blake3_256_hex: fileBlake3.toString('hex'),
    index_xxh64_hex: indexXxh64.toString('hex'),
    chunk_xxh64_hex: chunkXxh64.toString('hex'),
    layout: {
      header_len: HEADER_LEN,
      index_entry_len: INDEX_ENTRY_LEN,
      footer_len: FOOTER_LEN,
      index_count: indexCount,
      index_offset: indexOffset,
      index_length: indexLength,
      data_offset: dataOffset,
      data_length: dataLength,
      footer_offset: footerOffset
    }
  };
  return { fullFile, golden };
}
function writeArtifacts() {
  const repoRoot = path.resolve(__dirname, '..');
  const outDir = path.join(repoRoot, 'delivery', 'v0.9.1');
  fs.mkdirSync(outDir, { recursive: true });
  const { fullFile, golden } = buildMinimalHdiff();
  fs.writeFileSync(path.join(outDir, 'minimal.hdiff'), fullFile);
  fs.writeFileSync(path.join(outDir, 'golden-vector.json'), JSON.stringify(golden, null, 2));
  console.log('[OK] Wrote: delivery/v0.9.1/minimal.hdiff');
  console.log('[OK] Wrote: delivery/v0.9.1/golden-vector.json');
  console.log('[INFO] hash_algo=', golden.hash_algo);
}
if (require.main === module) {
  writeArtifacts();
}
module.exports = { buildMinimalHdiff };

/* FILE: scripts/verify-golden-vector.js */
// DEBT-VERIFY: 仅验证最小样例，未覆盖复杂场景和异常数据，P1级别
'use strict';
const fs = require('fs');
const path = require('path');
const crypto = require('crypto');
const { xxh64 } = require('../src/hash/xxh64');
const { blake3_256 } = require('../src/hash/blake3_256');
function mustRead(p) {
  if (!fs.existsSync(p)) throw new Error('Missing file: ' + p);
  return fs.readFileSync(p);
}
function main() {
  const repoRoot = path.resolve(__dirname, '..');
  const dir = path.join(repoRoot, 'delivery', 'v0.9.1');
  const fileBuf = mustRead(path.join(dir, 'minimal.hdiff'));
  const golden = JSON.parse(mustRead(path.join(dir, 'golden-vector.json')).toString('utf8'));
  const sha256 = crypto.createHash('sha256').update(fileBuf).digest('hex');
  if (sha256 !== golden.file_sha256) throw new Error('SHA256 mismatch');
  const footer = fileBuf.slice(fileBuf.length - 48);
  const expectedBlake3 = footer.slice(0, 32);
  const expectedIndexXxh64 = footer.slice(32, 40);
  const footerOffset = fileBuf.length - 48;
  const preFooter = fileBuf.slice(0, footerOffset);
  const actualBlake3 = blake3_256(preFooter);
  if (!actualBlake3.equals(expectedBlake3)) throw new Error('File BLAKE3 field mismatch');
  // index table bytes: header 指定 indexOffset/indexLength
  const indexOffset = Number(fileBuf.readBigUInt64LE(0x0B));
  const indexLength = Number(fileBuf.readBigUInt64LE(0x13));
  const indexTable = fileBuf.slice(indexOffset, indexOffset + indexLength);
  const actualIndexXxh64 = xxh64(indexTable, 0n);
  if (!actualIndexXxh64.equals(expectedIndexXxh64)) throw new Error('Index XXH64 mismatch');
  console.log('VERIFY_OK');
}
if (require.main === module) main();

/* FILE: src/hash/blake3_256.js */
// DEBT-B07-001: 纯JS实现无SIMD优化，性能可能慢 5-10x；侧信道防护未验证（请勿用于高对抗密钥场景）
'use strict';

// BLAKE3-256 (hash mode) — pure JS implementation
// Spec: https://c2sp.org/BLAKE3
// NOTE: This module intentionally does NOT use Node.js crypto APIs.

// --- Constants ---

// IV as 8 little-endian 32-bit words (same as SHA-256 IV / BLAKE2s IV)
const IV = Object.freeze([
  0x6A09E667, 0xBB67AE85, 0x3C6EF372, 0xA54FF53A,
  0x510E527F, 0x9B05688C, 0x1F83D9AB, 0x5BE0CD19,
]);

// Flags
const CHUNK_START = 1 << 0;
const CHUNK_END   = 1 << 1;
const PARENT      = 1 << 2;
const ROOT        = 1 << 3;

const BLOCK_LEN = 64;
const CHUNK_LEN = 1024;

// Message word permutation (applied after each round)
const MSG_PERM = Object.freeze([2, 6, 3, 10, 7, 0, 4, 13, 1, 11, 12, 5, 9, 14, 15, 8]);

// --- 32-bit helpers ,--

function rotr32(x, n) {
  return ((x >>> n) | (x << (32 - n))) >>> 0;
}

function g(v, a, b, c, d, x, y) {
  v[a] = (v[a] + v[b] + x) >>> 0;
  v[d] = rotr32(v[d] ^ v[a], 16);
  v[c] = (v[c] + v[d]) >>> 0;
  v[b] = rotr32(v[b] ^ v[c], 12);
  v[a] = (v[a] + v[b] + y) >>> 0;
  v[d] = rotr32(v[d] ^ v[a], 8);
  v[c] = (v[c] + v[d]) >>> 0;
  v[b] = rotr32(v[b] ^ v[c], 7);
}

function permute(m) {
  const tmp = new Array(16);
  for (let i = 0; i < 16; i++) tmp[i] = m[MSG_PERM[i]];
  for (let i = 0; i < 16; i++) m[i] = tmp[i];
}

function compress(h, m, t0, t1, blockLen, flags) {
  // Local working state v[0..15]
  const v = new Array(16);

  // v[0..7] := h
  for (let i = 0; i < 8; i++) v[i] = h[i] >>> 0;

  // v[8..11] := IV[0..3]
  v[8]  = IV[0];
  v[9]  = IV[1];
  v[10] = IV[2];
  v[11] = IV[3];

  // counter, block length, flags
  v[12] = t0 >>> 0;
  v[13] = t1 >>> 0;
  v[14] = blockLen >>> 0;
  v[15] = flags >>> 0;

  // We permute the message between rounds, so work on a copy.
  const block = m.slice(0, 16);

  for (let round = 0; round < 7; round++) {
    // Column rounds
    g(v, 0, 4,  8, 12, block[0], block[1]);
    g(v, 1, 5,  9, 13, block[2], block[3]);
    g(v, 2, 6, 10, 14, block[4], block[5]);
    g(v, 3, 7, 11, 15, block[6], block[7]);

    // Diagonal rounds
    g(v, 0, 5, 10, 15, block[8],  block[9]);
    g(v, 1, 6, 11, 12, block[10], block[11]);
    g(v, 2, 7,  8, 13, block[12], block[13]);
    g(v, 3, 4,  9, 14, block[14], block[15]);

    permute(block);
  }

  // Output state (untruncated)
  for (let i = 0; i < 8; i++) {
    v[i] = (v[i] ^ v[i + 8]) >>> 0;
    v[i + 8] = (v[i + 8] ^ h[i]) >>> 0;
  }

  return v;
}

function wordsFromBlock(blockBuf) {
  const m = new Array(16);
  for (let i = 0; i < 16; i++) m[i] = blockBuf.readUInt32LE(i * 4) >>> 0;
  return m;
}

function wordsToBytesLE(words) {
  const out = Buffer.alloc(words.length * 4);
  for (let i = 0; i < words.length; i++) out.writeUInt32LE(words[i] >>> 0, i * 4);
  return out;
}

function parentCv(leftCv, rightCv, isRoot) {
  // Parent message block is 64 bytes: leftCV (32) || rightCV (32)
  const m = new Array(16);
  for (let i = 0; i < 8; i++) m[i] = leftCv[i] >>> 0;
  for (let i = 0; i < 8; i++) m[8 + i] = rightCv[i] >>> 0;

  const flags = PARENT | (isRoot ? ROOT : 0);
  const out = compress(IV, m, 0, 0, BLOCK_LEN, flags);
  return out.slice(0, 8);
}

function chunkCv(input, chunkOffset, chunkLen, chunkIndex, isRootChunk) {
  // Start chaining value for a chunk is IV (hash mode)
  let cv = IV.slice(0, 8);

  const blockCount = (chunkLen === 0) ? 1 : Math.ceil(chunkLen / BLOCK_LEN);

  const t0 = Number(chunkIndex & 0xFFFFFFFFn) >>> 0;
  const t1 = Number((chunkIndex >> 32n) & 0xFFFFFFFFn) >>> 0;

  for (let blockIndex = 0; blockIndex < blockCount; blockIndex++) {
    const isLastBlock = (blockIndex === blockCount - 1);
    const blockStart = chunkOffset + blockIndex * BLOCK_LEN;

    const blockLen = isLastBlock ? (chunkLen - blockIndex * BLOCK_LEN) : BLOCK_LEN;

    const blockBuf = Buffer.alloc(BLOCK_LEN, 0);
    if (blockLen > 0) {
      input.copy(blockBuf, 0, blockStart, blockStart + blockLen);
    }

    const m = wordsFromBlock(blockBuf);

    let flags = 0;
    if (blockIndex === 0) flags |= CHUNK_START;
    if (isLastBlock) flags |= CHUNK_END;
    if (isRootChunk && isLastBlock) flags |= ROOT;

    const out = compress(cv, m, t0, t1, blockLen, flags);
    cv = out.slice(0, 8);
  }

  return cv;
}

function blake3_256(input) {
  const buf = Buffer.isBuffer(input) ? input : Buffer.from(input);
  const inputLen = buf.length;

  // BLAKE3 processes at least one chunk (even for empty input).
  const chunkCount = Math.max(1, Math.ceil(inputLen / CHUNK_LEN));

  // Single chunk: the chunk is also the root.
  if (chunkCount === 1) {
    const cv = chunkCv(buf, 0, inputLen, 0n, true);
    return wordsToBytesLE(cv); // 8 words -> 32 bytes
  }

  // Multi-chunk: build a Merkle tree using the chunk counter stack algorithm.
  const cvStack = [];

  for (let ci = 0; ci < chunkCount; ci++) {
    const chunkIndex = BigInt(ci);
    const chunkOfgset = ci * CHUNK_LEN;
    const chunkLen = Math.min(CHUNK_LEN, inputLen - chunkOffset);

    let cv = chunkCv(buf, chunkOffset, chunkLen, chunkIndex, false);

    // Merge completed subtrees (binary counter carry).
    let totalChunks = BigInt(ci + 1);
    while ((totalChunks & 1n) === 0n) {
      const left = cvStack.pop();
      cv = parentCv(left, cv, false);
      totalChunks >>= 1n;
    }

    cvStack.push(cv);
  }

  // Reduce stack to a single root CV.
  while (cvStack.length > 1) {
    const right = cvStack.pop();
    const left = cvStack.pop();
    const isRoot = (cvStack.length === 0);
    const cv = parentCv(left, right, isRoot);
    cvStack.push(cv);
  }

  return wordsToBytesLE(cvStack[0]);
}

module.exports = { blake3_256 };


/* FILE: src/hash/xxh64.js */
// DEBT-XXH64: 使用纯JS实现XXH64，性能低于原生实现，P1级别
'use strict';
/**
 * XXH64 (seed=0) - BigInt 实现，输出 uint64_le Buffer(8)
 * 说明：离线脚本用，优先保证确定性与跨平台一致。
 */
const MASK64 = (1n << 64n) - 1n;
const PRIME64_1 = 11400714785074694791n;
const PRIME64_2 = 14029467366897019727n;
const PRIME64_3 = 1609587929392839161n;
const PRIME64_4 = 9650029242287828579n;
const PRIME64_5 = 2870177450012600261n;
function rotl(x, r) {
  return ((x << BigInt(r)) | (x >> BigInt(64 - r))) & MASK64;
}
function readU32LE(buf, off) {
  return BigInt(buf.readUInt32LE(off)) & MASK64;
}
function readU64LE(buf, off) {
  // Node 的 readBigUInt64LE 可用，但这里手写以便更显式
  let x = 0n;
  for (let i = 0; i < 8; i++) {
    x |= BigInt(buf[off + i]) << (8n * BigInt(i));
  }
  return x & MASK64;
}
function round(acc, lane) {
  acc = (acc + (lane * PRIME64_2 & MASK64)) & MASK64;
  acc = rotl(acc, 31);
  acc = (acc * PRIME64_1) & MASK64;
  return acc;
}
function mergeRound(acc, val) {
  acc ^= round(0n, val);
  acc = (acc * PRIME64_1 + PRIME64_4) & MASK64;
  return acc;
}
function avalanche(h) {
  h ^= (h >> 33n);
  h = (h * PRIME64_2) & MASK64;
  h ^= (h >> 29n);
  h = (h * PRIME64_3) & MASK64;
  h ^= (h >> 32n);
  return h & MASK64;
}
function toU64LEBuffer(x) {
  const b = Buffer.alloc(8);
  let v = x & MASK64;
  for (let i = 0; i < 8; i++) {
    b[i] = Number((v >> (8n * BigInt(i))) & 0xFFn);
  }
  return b;
}
function xxh64(buf, seed = 0n) {
  let p = 0;
  const len = buf.length;
  let h64;
  if (len >= 32) {
    let v1 = (seed + PRIME64_1 + PRIME64_2) & MASK64;
    let v2 = (seed + PRIME64_2) & MASK64;
    let v3 = seed & MASK64;
    let v4 = (seed - PRIME64_1) & MASK64;
    const limit = len - 32;
    while (p <= limit) {
      v1 = round(v1, readU64LE(buf, p)); p += 8;
      v2 = round(v2, readU64LE(buf, p)); p += 8;
      v3 = round(v3, readU64LE(buf, p)); p += 8;
      v4 = round(v4, readU64LE(buf, p)); p += 8;
    }
    h64 = (rotl(v1, 1) + rotl(v2, 7) + rotl(v3, 12) + rotl(v4, 18)) & MASK64;
    h64 = mergeRound(h64, v1);
    h64 = mergeRound(h64, v2);
    h64 = mergeRound(h64, v3);
    h64 = mergeRound(h64, v4);
  } else {
    h64 = (seed + PRIME64_5) & MASK64;
  }
  h64 = (h64 + BigInt(len)) & MASK64;
  while (p + 8 <= len) {
    const k1 = round(0n, readU64LE(buf, p));
    h64 ^= k1;
    h64 = (rotl(h64, 27) * PRIME64_1 + PRIME64_4) & MASK64;
    p += 8;
  }
  if (p + 4 <= len) {
    h64 ^= (readU32LE(buf, p) * PRIME64_1) & MASK64;
    h64 = (rotl(h64, 23) * PRIME64_2 + PRIME64_3) & MASK64;
    p += 4;
  }
  while (p < len) {
    h64 ^= (BigInt(buf[p]) * PRIME64_5) & MASK64;
    h64 = (rotl(h64, 11) * PRIME64_1) & MASK64;
    p += 1;
  }
  return toU64LEBuffer(avalanche(h64));
}
module.exports = { xxh64 };

// mutated-seed:1337
